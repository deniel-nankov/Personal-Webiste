{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "1f9ccb45",
            "metadata": {},
            "source": [
                "# FX Carry Strategy - Phase 2: Advanced Analysis\n",
                "# Verdad Technical Case Study\n",
                "\n",
                "## Overview\n",
                "This notebook extends the baseline carry strategy analysis with advanced quantitative techniques:\n",
                "\n",
                "**Phase 2 Enhancements:**\n",
                "1. **Factor Decomposition Analysis** - Understand what drives carry returns\n",
                "2. **Multi-Signal Framework** - Test additional predictive signals beyond volatility\n",
                "3. **Machine Learning Models** - Use ML to predict return regimes\n",
                "4. **Portfolio Optimization** - Find optimal weights using mean-variance optimization\n",
                "\n",
                "**Data Sources:**\n",
                "- Baseline carry strategy returns (from Phase 1)\n",
                "- Additional macro data: VIX, credit spreads, term spreads, commodities, dollar index\n",
                "- Factor returns: equity, bonds, commodities\n",
                "\n",
                "**Date:** November 4, 2025"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "99096dec",
            "metadata": {},
            "source": [
                "## Setup: Import Libraries and Load Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "06e8bb62",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "✓ Libraries imported successfully\n",
                        "NumPy version: 2.3.4\n",
                        "Pandas version: 2.3.3\n"
                    ]
                }
            ],
            "source": [
                "# Import all required libraries\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from scipy import stats\n",
                "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.model_selection import train_test_split, cross_val_score\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "# Plotting settings\n",
                "plt.style.use('seaborn-v0_8-darkgrid')\n",
                "sns.set_palette(\"husl\")\n",
                "pd.set_option('display.max_columns', None)\n",
                "pd.set_option('display.precision', 4)\n",
                "\n",
                "print(\"✓ Libraries imported successfully\")\n",
                "print(f\"NumPy version: {np.__version__}\")\n",
                "print(f\"Pandas version: {pd.__version__}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "9e1cd1ad",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading Phase 1 baseline data...\n",
                        "✓ Loaded exchange rates: (9133, 8)\n",
                        "✓ Loaded spot rates: (9133, 8)\n",
                        "✓ Loaded equity returns: (6293, 1)\n",
                        "✓ Loaded fed funds: (9133, 1)\n"
                    ]
                }
            ],
            "source": [
                "# Load baseline strategy returns from Phase 1\n",
                "print(\"Loading Phase 1 baseline data...\")\n",
                "\n",
                "# We'll need to reconstruct key variables from Phase 1\n",
                "# Load the raw data\n",
                "exchange_rates = pd.read_csv('verdad_fx_case_study_data.csv', skiprows=39, nrows=9134)\n",
                "exchange_rates = exchange_rates.dropna(how='all')\n",
                "exchange_rates['DAY_DATE'] = pd.to_datetime(exchange_rates['DAY_DATE'], errors='coerce')\n",
                "exchange_rates = exchange_rates.dropna(subset=['DAY_DATE'])\n",
                "exchange_rates = exchange_rates.set_index('DAY_DATE')\n",
                "if 'USD_EXCH_RATE' in exchange_rates.columns:\n",
                "    exchange_rates = exchange_rates.drop('USD_EXCH_RATE', axis=1)\n",
                "for col in exchange_rates.columns:\n",
                "    exchange_rates[col] = pd.to_numeric(exchange_rates[col], errors='coerce')\n",
                "\n",
                "spot_rates = pd.read_csv('verdad_fx_case_study_data.csv', skiprows=9175, nrows=9134)\n",
                "spot_rates = spot_rates.dropna(how='all')\n",
                "spot_rates['DAY_DATE'] = pd.to_datetime(spot_rates['DAY_DATE'], errors='coerce')\n",
                "spot_rates = spot_rates.dropna(subset=['DAY_DATE'])\n",
                "spot_rates = spot_rates.set_index('DAY_DATE')\n",
                "for col in spot_rates.columns:\n",
                "    spot_rates[col] = pd.to_numeric(spot_rates[col], errors='coerce')\n",
                "\n",
                "equity_returns = pd.read_csv('verdad_fx_case_study_data.csv', skiprows=18311, nrows=6294)\n",
                "equity_returns = equity_returns.dropna(how='all')\n",
                "equity_returns['DAY_DATE'] = pd.to_datetime(equity_returns['DAY_DATE'], errors='coerce')\n",
                "equity_returns = equity_returns.dropna(subset=['DAY_DATE'])\n",
                "equity_returns = equity_returns.set_index('DAY_DATE')\n",
                "if 'DIRECTION' in equity_returns.columns:\n",
                "    equity_returns = equity_returns.drop('DIRECTION', axis=1)\n",
                "equity_returns = equity_returns.loc[:, ~equity_returns.columns.str.contains('Unnamed')]\n",
                "for col in equity_returns.columns:\n",
                "    equity_returns[col] = pd.to_numeric(equity_returns[col], errors='coerce')\n",
                "\n",
                "fed_funds = pd.read_csv('verdad_fx_case_study_data.csv', skiprows=24607)\n",
                "fed_funds = fed_funds.dropna(how='all')\n",
                "fed_funds['DAY_DATE'] = pd.to_datetime(fed_funds['DAY_DATE'], errors='coerce')\n",
                "fed_funds = fed_funds.dropna(subset=['DAY_DATE'])\n",
                "fed_funds = fed_funds.set_index('DAY_DATE')\n",
                "fed_funds = fed_funds.loc[:, ~fed_funds.columns.str.contains('Unnamed')]\n",
                "for col in fed_funds.columns:\n",
                "    fed_funds[col] = pd.to_numeric(fed_funds[col], errors='coerce')\n",
                "\n",
                "print(f\"✓ Loaded exchange rates: {exchange_rates.shape}\")\n",
                "print(f\"✓ Loaded spot rates: {spot_rates.shape}\")\n",
                "print(f\"✓ Loaded equity returns: {equity_returns.shape}\")\n",
                "print(f\"✓ Loaded fed funds: {fed_funds.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "0b274487",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "✓ Reconstructed baseline strategy\n",
                        "  Strategy returns: 9102 observations\n",
                        "  Date range: 2000-02-01 00:00:00 to 2025-01-01 00:00:00\n",
                        "  Mean daily return: -0.85 bps\n",
                        "  Annualized Sharpe: -0.232\n"
                    ]
                }
            ],
            "source": [
                "# Reconstruct excess returns and strategy (from Phase 1)\n",
                "currencies = ['AUD', 'BRL', 'CAD', 'CHF', 'EUR', 'GBP', 'JPY', 'MXN']\n",
                "\n",
                "# Calculate excess returns\n",
                "exch_log_returns = pd.DataFrame(index=exchange_rates.index)\n",
                "for curr in currencies:\n",
                "    exch_col = f'{curr}_EXCH_RATE'\n",
                "    exch_log_returns[curr] = -np.log(exchange_rates[exch_col] / exchange_rates[exch_col].shift(1))\n",
                "\n",
                "int_rate_diff = pd.DataFrame(index=spot_rates.index)\n",
                "for curr in currencies:\n",
                "    spot_col = f'{curr}_RF_RATE'\n",
                "    int_rate_diff[curr] = (spot_rates[spot_col] - fed_funds['USD_RF_RATE']) / 252 / 100\n",
                "\n",
                "common_index = exch_log_returns.index.intersection(int_rate_diff.index)\n",
                "excess_returns = pd.DataFrame(index=common_index)\n",
                "for curr in currencies:\n",
                "    excess_returns[curr] = (exch_log_returns.loc[common_index, curr] + \n",
                "                            int_rate_diff.loc[common_index, curr])\n",
                "excess_returns = excess_returns.dropna()\n",
                "\n",
                "# Build baseline strategy\n",
                "int_diff = pd.DataFrame(index=spot_rates.index)\n",
                "for curr in currencies:\n",
                "    spot_col = f'{curr}_RF_RATE'\n",
                "    int_diff[curr] = spot_rates[spot_col] - fed_funds['USD_RF_RATE']\n",
                "\n",
                "month_ends = excess_returns.resample('M').last().index\n",
                "weights = pd.DataFrame(0.0, index=excess_returns.index, columns=currencies)\n",
                "\n",
                "for i, month_end in enumerate(month_ends):\n",
                "    if month_end in int_diff.index:\n",
                "        month_diff = int_diff.loc[month_end]\n",
                "        ranked = month_diff.sort_values(ascending=False)\n",
                "        long_currencies = ranked.head(3).index.tolist()\n",
                "        short_currencies = ranked.tail(3).index.tolist()\n",
                "        \n",
                "        if i < len(month_ends) - 1:\n",
                "            next_month_end = month_ends[i + 1]\n",
                "            holding_dates = excess_returns.loc[month_end:next_month_end].index[1:]\n",
                "        else:\n",
                "            holding_dates = excess_returns.loc[month_end:].index[1:]\n",
                "        \n",
                "        if len(holding_dates) > 0:\n",
                "            weights.loc[holding_dates, long_currencies] = 1/3\n",
                "            weights.loc[holding_dates, short_currencies] = -1/3\n",
                "\n",
                "strategy_returns = (weights * excess_returns).sum(axis=1)\n",
                "strategy_returns = strategy_returns[strategy_returns != 0]\n",
                "\n",
                "print(f\"\\n✓ Reconstructed baseline strategy\")\n",
                "print(f\"  Strategy returns: {len(strategy_returns)} observations\")\n",
                "print(f\"  Date range: {strategy_returns.index.min()} to {strategy_returns.index.max()}\")\n",
                "print(f\"  Mean daily return: {strategy_returns.mean()*10000:.2f} bps\")\n",
                "print(f\"  Annualized Sharpe: {(strategy_returns.mean() / strategy_returns.std()) * np.sqrt(252):.3f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "23babd59",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading Phase 2 macro data...\n",
                        "✓ Loaded macro data: (9440, 36)\n",
                        "  Date range: 2000-01-01 00:00:00 to 2025-11-04 00:00:00\n",
                        "  Total columns: 36\n",
                        "  Sample columns: ['VIX', 'Treasury_10Y', 'Treasury_2Y', 'Treasury_3M', 'Term_Spread']...\n"
                    ]
                }
            ],
            "source": [
                "# Load additional macro data\n",
                "print(\"Loading Phase 2 macro data...\")\n",
                "\n",
                "try:\n",
                "    macro_data = pd.read_csv('additional_macro_data.csv', index_col=0, parse_dates=True)\n",
                "    print(f\"✓ Loaded macro data: {macro_data.shape}\")\n",
                "    print(f\"  Date range: {macro_data.index.min()} to {macro_data.index.max()}\")\n",
                "    print(f\"  Total columns: {len(macro_data.columns)}\")\n",
                "    print(f\"  Sample columns: {list(macro_data.columns[:5])}...\")\n",
                "except FileNotFoundError:\n",
                "    print(\"⚠ additional_macro_data.csv not found!\")\n",
                "    print(\"  Run download_additional_data.py first to fetch macro data\")\n",
                "    macro_data = pd.DataFrame()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ceb16e5d",
            "metadata": {},
            "source": [
                "### Data Sources Summary\n",
                "\n",
                "**Phase 2 Analysis uses multiple data sources:**\n",
                "\n",
                "1. **Baseline Data** (from verdad_fx_case_study_data.csv):\n",
                "   - Exchange rates for 8 currencies\n",
                "   - Spot interest rates\n",
                "   - S&P 500 total returns\n",
                "   - Fed Funds rate\n",
                "\n",
                "2. **FRED API Data** (from download_additional_data.py):\n",
                "   - VIX, Treasury yields (10Y, 2Y, 3M)\n",
                "   - Credit spreads (IG, HY)\n",
                "   - Term spread, TED spread\n",
                "   - Dollar Index, CPI, Unemployment\n",
                "\n",
                "3. **Yahoo Finance Data** (yfinance):\n",
                "   - Dollar Index (DXY)\n",
                "   - Commodity indices and prices\n",
                "   - Bond ETF returns (TLT, IEF, LQD, HYG)\n",
                "   - Global equity indices\n",
                "   - Regional equity ETFs\n",
                "\n",
                "All data is merged below and available for factor analysis."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "f3b18627",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "================================================================================\n",
                        "ENHANCING MACRO DATA WITH YFINANCE SOURCES\n",
                        "================================================================================\n",
                        "  ✓ VIX_yf               (6,289 obs)\n",
                        "  ✓ DXY_yf               (6,316 obs)\n",
                        "  ✓ Commodities_yf       (4,758 obs)\n",
                        "  ✓ Gold_yf              (6,106 obs)\n",
                        "  ✓ Oil_yf               (6,115 obs)\n",
                        "  ✓ Silver_yf            (6,108 obs)\n",
                        "  ✓ TLT_yf               (5,645 obs)\n",
                        "  ✓ IEF_yf               (5,645 obs)\n",
                        "  ✓ LQD_yf               (5,645 obs)\n",
                        "  ✓ HYG_yf               (4,463 obs)\n",
                        "  ✓ SPX_yf               (6,289 obs)\n",
                        "  ✓ DJI_yf               (6,289 obs)\n",
                        "  ✓ FTSE_yf              (6,314 obs)\n",
                        "  ✓ Nikkei_yf            (6,126 obs)\n",
                        "  ✓ EEM_yf               (5,467 obs)\n",
                        "\n",
                        "✓ Loaded 15/15 series from yfinance\n",
                        "\n",
                        "================================================================================\n",
                        "COMBINED DATASET SUMMARY\n",
                        "================================================================================\n",
                        "Shape: 9,440 rows × 51 columns\n",
                        "Dates: 2000-01-01 to 2025-11-04\n",
                        "Memory: 3.7 MB\n",
                        "\n",
                        "Sample data availability (first 10 series):\n",
                        "  VIX                        6,526 obs ( 69.1%)\n",
                        "  Treasury_10Y               6,463 obs ( 68.5%)\n",
                        "  Treasury_2Y                6,463 obs ( 68.5%)\n",
                        "  Treasury_3M                6,463 obs ( 68.5%)\n",
                        "  Term_Spread                6,464 obs ( 68.5%)\n",
                        "  IG_Spread                  6,745 obs ( 71.5%)\n",
                        "  HY_Spread                  6,746 obs ( 71.5%)\n",
                        "  TED_Spread                 5,412 obs ( 57.3%)\n",
                        "  Dollar_Index               4,973 obs ( 52.7%)\n",
                        "  Fed_Funds                  9,439 obs (100.0%)\n",
                        "\n",
                        "Total data sources:\n",
                        "  FRED API: 24 series\n",
                        "  Yahoo Finance: 15 series\n",
                        "  Derived returns: 12 series\n",
                        "\n",
                        "✅ Integration complete in 1.1 seconds\n"
                    ]
                }
            ],
            "source": [
                "# Enhance macro_data with yfinance data - OPTIMIZED VERSION\n",
                "import time\n",
                "start_time = time.time()\n",
                "\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"ENHANCING MACRO DATA WITH YFINANCE SOURCES\")\n",
                "print(\"=\"*80)\n",
                "\n",
                "yf_files = {\n",
                "    'VIX_yf': 'yf_vix.csv',\n",
                "    'DXY_yf': 'yf_dollar_index.csv',\n",
                "    'Commodities_yf': 'yf_commodity_index.csv',\n",
                "    'Gold_yf': 'yf_gold_futures.csv',\n",
                "    'Oil_yf': 'yf_crude_oil_wti.csv',\n",
                "    'Silver_yf': 'yf_silver_futures.csv',\n",
                "    'TLT_yf': 'yf_tlt.csv',\n",
                "    'IEF_yf': 'yf_ief.csv',\n",
                "    'LQD_yf': 'yf_lqd.csv',\n",
                "    'HYG_yf': 'yf_hyg.csv',\n",
                "    'SPX_yf': 'yf_gspc.csv',\n",
                "    'DJI_yf': 'yf_dji.csv',\n",
                "    'FTSE_yf': 'yf_ftse.csv',\n",
                "    'Nikkei_yf': 'yf_n225.csv',\n",
                "    'EEM_yf': 'yf_eem.csv'\n",
                "}\n",
                "\n",
                "yf_loaded = 0\n",
                "for name, filename in yf_files.items():\n",
                "    try:\n",
                "        df = pd.read_csv(filename, index_col=0, parse_dates=True)\n",
                "        if 'Close' in df.columns:\n",
                "            macro_data[name] = df['Close']\n",
                "        elif len(df.columns) == 1:\n",
                "            macro_data[name] = df.iloc[:, 0]\n",
                "        print(f\"  ✓ {name:20s} ({len(df):,} obs)\")\n",
                "        yf_loaded += 1\n",
                "    except FileNotFoundError:\n",
                "        print(f\"  ⚠ {name:20s} file not found\")\n",
                "    except Exception as e:\n",
                "        print(f\"  ✗ {name:20s} error\")\n",
                "\n",
                "print(f\"\\n✓ Loaded {yf_loaded}/15 series from yfinance\")\n",
                "\n",
                "print(\"\\n\" + \"=\"*80)\n",
                "print(\"COMBINED DATASET SUMMARY\")\n",
                "print(\"=\"*80)\n",
                "print(f\"Shape: {macro_data.shape[0]:,} rows × {macro_data.shape[1]} columns\")\n",
                "print(f\"Dates: {macro_data.index.min().date()} to {macro_data.index.max().date()}\")\n",
                "print(f\"Memory: {macro_data.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
                "\n",
                "# Fast sample of data availability (first 10 columns only to avoid slowdown)\n",
                "print(f\"\\nSample data availability (first 10 series):\")\n",
                "for col in macro_data.columns[:10]:\n",
                "    count = macro_data[col].notna().sum()\n",
                "    pct = (count / len(macro_data) * 100)\n",
                "    print(f\"  {col:25s} {count:6,} obs ({pct:5.1f}%)\")\n",
                "\n",
                "print(f\"\\nTotal data sources:\")\n",
                "fred_cols = len([c for c in macro_data.columns if not c.endswith('_yf') and not c.endswith('_Return')])\n",
                "yf_cols = len([c for c in macro_data.columns if c.endswith('_yf')])\n",
                "derived = len([c for c in macro_data.columns if c.endswith('_Return')])\n",
                "print(f\"  FRED API: {fred_cols} series\")\n",
                "print(f\"  Yahoo Finance: {yf_cols} series\")\n",
                "print(f\"  Derived returns: {derived} series\")\n",
                "\n",
                "elapsed = time.time() - start_time\n",
                "print(f\"\\n✅ Integration complete in {elapsed:.1f} seconds\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "aff50b08",
            "metadata": {},
            "source": [
                "## Section 1: Factor Decomposition Analysis\n",
                "\n",
                "Decompose carry strategy returns into systematic factor exposures using regression analysis. This helps us understand:\n",
                "- How much of carry returns come from equity beta?\n",
                "- Is there exposure to bonds, commodities, or the dollar?\n",
                "- What's the \"pure alpha\" after controlling for these factors?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "fa1c324c",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Building factor return series...\n",
                        "\n",
                        "✓ Factor data prepared\n",
                        "  Observations: 9102\n",
                        "\n",
                        "Factor correlations with strategy:\n",
                        "Commodities    0.2598\n",
                        "Dollar         0.1729\n",
                        "Equity        -0.0415\n",
                        "Bonds         -0.2284\n",
                        "Name: Strategy, dtype: float64\n"
                    ]
                }
            ],
            "source": [
                "# Build factor return series\n",
                "print(\"Building factor return series...\")\n",
                "\n",
                "# Align dates\n",
                "common_dates = strategy_returns.index\n",
                "\n",
                "# Equity factor (already have S&P 500)\n",
                "equity_factor = equity_returns['SPX_TR'].reindex(common_dates).fillna(0)\n",
                "\n",
                "# Other factors from macro data\n",
                "if not macro_data.empty:\n",
                "    # Bond factor\n",
                "    if 'Bonds_20Y_Return' in macro_data.columns:\n",
                "        bond_factor = macro_data['Bonds_20Y_Return'].reindex(common_dates).fillna(0)\n",
                "    else:\n",
                "        bond_factor = pd.Series(0, index=common_dates)\n",
                "    \n",
                "    # Commodity factor\n",
                "    if 'Commodities_Return' in macro_data.columns:\n",
                "        commodity_factor = macro_data['Commodities_Return'].reindex(common_dates).fillna(0)\n",
                "    else:\n",
                "        commodity_factor = pd.Series(0, index=common_dates)\n",
                "    \n",
                "    # Dollar factor\n",
                "    if 'DXY' in macro_data.columns:\n",
                "        dollar_returns = macro_data['DXY'].pct_change().reindex(common_dates).fillna(0)\n",
                "    else:\n",
                "        dollar_returns = pd.Series(0, index=common_dates)\n",
                "else:\n",
                "    bond_factor = pd.Series(0, index=common_dates)\n",
                "    commodity_factor = pd.Series(0, index=common_dates)\n",
                "    dollar_returns = pd.Series(0, index=common_dates)\n",
                "\n",
                "# Combine into factor DataFrame\n",
                "factors = pd.DataFrame({\n",
                "    'Equity': equity_factor,\n",
                "    'Bonds': bond_factor,\n",
                "    'Commodities': commodity_factor,\n",
                "    'Dollar': dollar_returns,\n",
                "    'Strategy': strategy_returns\n",
                "})\n",
                "\n",
                "factors = factors.dropna()\n",
                "\n",
                "print(f\"\\n✓ Factor data prepared\")\n",
                "print(f\"  Observations: {len(factors)}\")\n",
                "print(f\"\\nFactor correlations with strategy:\")\n",
                "print(factors.corr()['Strategy'].drop('Strategy').sort_values(ascending=False))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "d65f02d9",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "================================================================================\n",
                        "FACTOR DECOMPOSITION RESULTS\n",
                        "================================================================================\n",
                        "\n",
                        "Alpha (Intercept): -0.8118 bps/day\n",
                        "R-squared: 0.1524\n",
                        "\n",
                        "Factor Exposures:\n",
                        "     Factor    Beta   T-stat  P-value Significant\n",
                        "     Equity -0.0122  -2.2097   0.0271          **\n",
                        "      Bonds -0.1150 -14.2436   0.0000         ***\n",
                        "Commodities  0.1944  28.4597   0.0000         ***\n",
                        "     Dollar  0.3480  23.9015   0.0000         ***\n",
                        "\n",
                        "Residual Volatility (Pure Alpha): 8.47%\n",
                        "Residual Sharpe: -0.000\n"
                    ]
                }
            ],
            "source": [
                "# Run factor regression\n",
                "from sklearn.linear_model import LinearRegression\n",
                "\n",
                "# Prepare X (factors) and y (strategy returns)\n",
                "X = factors[['Equity', 'Bonds', 'Commodities', 'Dollar']]\n",
                "y = factors['Strategy']\n",
                "\n",
                "# Fit regression\n",
                "model = LinearRegression()\n",
                "model.fit(X, y)\n",
                "\n",
                "# Calculate metrics\n",
                "y_pred = model.predict(X)\n",
                "residuals = y - y_pred\n",
                "r_squared = model.score(X, y)\n",
                "\n",
                "# Statistical significance\n",
                "n = len(X)\n",
                "k = X.shape[1]\n",
                "se = np.sqrt(np.sum(residuals**2) / (n - k - 1))\n",
                "X_with_const = np.column_stack([np.ones(n), X])\n",
                "var_coef = se**2 * np.linalg.inv(X_with_const.T @ X_with_const).diagonal()[1:]\n",
                "t_stats = model.coef_ / np.sqrt(var_coef)\n",
                "p_values = 2 * (1 - stats.t.cdf(np.abs(t_stats), n - k - 1))\n",
                "\n",
                "# Results table\n",
                "factor_results = pd.DataFrame({\n",
                "    'Factor': X.columns,\n",
                "    'Beta': model.coef_,\n",
                "    'T-stat': t_stats,\n",
                "    'P-value': p_values,\n",
                "    'Significant': ['***' if p < 0.01 else '**' if p < 0.05 else '*' if p < 0.1 else '' for p in p_values]\n",
                "})\n",
                "\n",
                "print(\"=\"*80)\n",
                "print(\"FACTOR DECOMPOSITION RESULTS\")\n",
                "print(\"=\"*80)\n",
                "print(f\"\\nAlpha (Intercept): {model.intercept_*10000:.4f} bps/day\")\n",
                "print(f\"R-squared: {r_squared:.4f}\")\n",
                "print(f\"\\nFactor Exposures:\")\n",
                "print(factor_results.to_string(index=False))\n",
                "print(f\"\\nResidual Volatility (Pure Alpha): {residuals.std() * np.sqrt(252) * 100:.2f}%\")\n",
                "print(f\"Residual Sharpe: {(residuals.mean() / residuals.std()) * np.sqrt(252):.3f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6414f9d5",
            "metadata": {},
            "source": [
                "**Interpretation:** The factor decomposition reveals that the FX carry strategy is not a \"pure alpha\" strategy but rather has significant exposures to systematic risk factors. The most prominent exposure is to the US dollar (beta = 0.348), followed by commodities (beta = 0.194). The strategy shows negative exposure to bonds (beta = -0.115) and a small negative equity beta (-0.012). However, these factor exposures only explain 15.2% of the strategy's variance (R² = 0.152), meaning the majority of returns are driven by other factors. After accounting for these systematic exposures, the pure alpha is -0.81 bps/day (still negative), with a residual Sharpe ratio near zero. This suggests that the carry strategy's poor performance cannot be fully attributed to adverse factor exposures alone—it has fundamental issues beyond just being \"long the wrong factors.\""
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ce5be651",
            "metadata": {},
            "source": [
                "### What This Shows\n",
                "\n",
                "The factor decomposition reveals how much of the carry strategy's returns can be explained by common market factors versus idiosyncratic carry risk. The beta coefficients tell us the strategy's exposure to each factor—for example, a positive equity beta means the strategy tends to move with stock markets. The R-squared indicates what percentage of return variance is explained by these factors, with the remainder being \"pure alpha\" specific to the carry trade itself.\n",
                "\n",
                "Statistically significant exposures (marked with asterisks) indicate systematic relationships that persist over time. The alpha (intercept) represents the return after controlling for all factor exposures—this is the true value-add from the carry strategy itself. The residual volatility and Sharpe ratio show how the strategy performs after stripping out factor exposures. If the residual Sharpe is higher than the raw Sharpe, it suggests the strategy could benefit from hedging those factor exposures."
            ]
        }
    ]
}